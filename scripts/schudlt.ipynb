{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7696f1da",
   "metadata": {},
   "source": [
    "# Human Action Classifier\n",
    "**Schuldt et al. 2004. Recognizing Human Actions: A Local SVM Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c806d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592dfa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b8707",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f427c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 400\n",
    "ACTIONS = [\"boxing\", \"handclapping\", \"handwaving\", \"jogging\", \"running\", \"walking\" ]\n",
    "action_to_id = {a: i for i, a in enumerate(ACTIONS)}\n",
    "pattern = re.compile(r\"person(?P<person>\\d+)_(?P<action>[a-z]+)_d(?P<scene>\\d)\")\n",
    "\n",
    "def index_data(root=\"Data\"):\n",
    "    samples = []\n",
    "    for video in Path(root).glob(\"*.avi\"):\n",
    "        match = pattern.search(video.name)\n",
    "        if match is None:\n",
    "            continue\n",
    "        samples.append({\n",
    "            \"path\": video,\n",
    "            \"label\": action_to_id[match.group(\"action\")],\n",
    "            \"action\": match.group(\"action\"),\n",
    "            \"person\": int(match.group(\"person\")),\n",
    "            \"scene\": int(match.group(\"scene\")),\n",
    "        })\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8dadf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: Counter({'boxing': 100, 'running': 100, 'handwaving': 100, 'walking': 100, 'jogging': 100, 'handclapping': 99})\n",
      "Train: 407 Validation: 96 Test: 96\n"
     ]
    }
   ],
   "source": [
    "# Import all data\n",
    "samples = index_data()\n",
    "print(\"Total:\", Counter(s[\"action\"] for s in samples))\n",
    "\n",
    "# Train/validation/test split (70-15-15)\n",
    "train_samples = [s for s in samples if s[\"person\"] <= 17]\n",
    "val_samples = [s for s in samples if 17 < s[\"person\"] <= 21]\n",
    "test_samples = [s for s in samples if s[\"person\"] > 21]\n",
    "print(\"Train:\", len(train_samples), \"Validation:\", len(val_samples), \"Test:\", len(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7751faa7",
   "metadata": {},
   "source": [
    "### 2. Data Processing\n",
    "#### 2.1. Transform Video To Image Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e320311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, resize=(160, 120)):\n",
    "    cap = cv2.VideoCapture(str(path))\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.resize(frame, resize)\n",
    "        frame = frame.astype(np.float32) / 255.0\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    video = np.stack(frames)   # (T, H, W)\n",
    "    return torch.from_numpy(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10daa860",
   "metadata": {},
   "source": [
    "#### 2.2. Construct Gaussian Scale Space\n",
    "$$L(路 , \\sigma^2, \\tau^2) = f \\times g(路 , \\sigma^2, \\tau^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be76b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_1d(kernel_size, sigma):\n",
    "    x = torch.arange(kernel_size) - kernel_size // 2\n",
    "    g = torch.exp(-(x ** 2) / (2 * (sigma ** 2)))\n",
    "    return g / g.sum()\n",
    "\n",
    "def gaussian_blur_3d(video, sigma, tau):\n",
    "    # spatial blur\n",
    "    g_xy = gaussian_1d(7, sigma)\n",
    "    g_xy = g_xy[None, None, :, None] * g_xy[None, None, None, :]\n",
    "    video = F.conv2d(video.unsqueeze(1), g_xy, padding=3).squeeze(1)\n",
    "\n",
    "    # temporal blur\n",
    "    g_t = gaussian_1d(7, tau)[None, None, :, None, None]\n",
    "    video = F.conv3d(video.unsqueeze(0), g_t, padding=(3,0,0)).squeeze(0)\n",
    "\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9ed1b",
   "metadata": {},
   "source": [
    "#### 2.3. Compute Second-moment Matrix From Spatio-temporal Gradients\n",
    "\n",
    "$$\\nabla L = (L_x, L_y, L_t)^T$$\n",
    "$$\\mu(路; \\sigma^2, \\tau^2) = g(路; s\\sigma^2, s\\tau^2) \\times (\\nabla L(\\nabla L)^T)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa96346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_3d(L):\n",
    "\tLx = L[:, :, 2:] - L[:, :, :-2]\n",
    "\tLy = L[:, 2:, :] - L[:, :-2, :]\n",
    "\tLt = L[2:, :, :] - L[:-2, :, :]\n",
    "\n",
    "\tT = min(Lx.shape[0], Ly.shape[0], Lt.shape[0])\n",
    "\tH = min(Lx.shape[1], Ly.shape[1], Lt.shape[1])\n",
    "\tW = min(Lx.shape[2], Ly.shape[2], Lt.shape[2])\n",
    "\n",
    "\treturn Lx[:T, :H, :W], Ly[:T, :H, :W], Lt[:T, :H, :W]\n",
    "\n",
    "def second_moment_matrix(Lx, Ly, Lt, sigma=2.0, tau=1.5):\n",
    "    J_xx = Lx * Lx\n",
    "    J_xy = Lx * Ly\n",
    "    J_xt = Lx * Lt\n",
    "    J_yy = Ly * Ly\n",
    "    J_yt = Ly * Lt\n",
    "    J_tt = Lt * Lt\n",
    "\n",
    "    def smooth(x):\n",
    "        return gaussian_blur_3d(x, sigma, tau)\n",
    "\n",
    "    return smooth(J_xx), smooth(J_xy), smooth(J_xt), smooth(J_yy), smooth(J_yt), smooth(J_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5d50f",
   "metadata": {},
   "source": [
    "#### 2.4. Detect Interest Point Using Harris Response\n",
    "\n",
    "$$H = det(\\mu) - k * trace^3(\\mu)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a46e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_response(J, k=0.005):\n",
    "    J_xx, J_xy, J_xt, J_yy, J_yt, J_tt = J\n",
    "\n",
    "    det = (\n",
    "        J_xx * (J_yy * J_tt - J_yt ** 2)\n",
    "        - J_xy * (J_xy * J_tt - J_xt * J_yt)\n",
    "        + J_xt * (J_xy * J_yt - J_xt * J_yy)\n",
    "    )\n",
    "\n",
    "    trace = J_xx + J_yy + J_tt\n",
    "    return det - k * trace ** 3\n",
    "\n",
    "def detect_interest_points(H, threshold_ratio=0.01):\n",
    "    threshold = threshold_ratio * H.max()\n",
    "    points = torch.nonzero(H > threshold)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df45348",
   "metadata": {},
   "source": [
    "#### 2.5. Extract Spatio-temporal Descriptors\n",
    "\n",
    "$$\\bold{l} = (L_x, L_y, L_t, L_{xx}, ..., L_{tttt}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00427c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jet(L, x, y, t, sigma, tau):\n",
    "    # first order\n",
    "    Lx = L[t, y, x+1] - L[t, y, x-1]\n",
    "    Ly = L[t, y+1, x] - L[t, y-1, x]\n",
    "    Lt = L[t+1, y, x] - L[t-1, y, x]\n",
    "\n",
    "    # second order\n",
    "    Lxx = L[t, y, x+1] - 2*L[t, y, x] + L[t, y, x-1]\n",
    "    Lyy = L[t, y+1, x] - 2*L[t, y, x] + L[t, y-1, x]\n",
    "    Ltt = L[t+1, y, x] - 2*L[t, y, x] + L[t-1, y, x]\n",
    "\n",
    "    jet = torch.tensor([\n",
    "        sigma * Lx, sigma * Ly, tau * Lt,\n",
    "        sigma**2 * Lxx, sigma**2 * Lyy, tau**2 * Ltt\n",
    "    ], device=L.device)\n",
    "\n",
    "    return jet\n",
    "\n",
    "def extract_descriptors(video, sigma=1.5, tau=1.0):\n",
    "    L = gaussian_blur_3d(video, sigma, tau)\n",
    "    Lx, Ly, Lt = gradients_3d(L)\n",
    "    J = second_moment_matrix(Lx, Ly, Lt, 2*sigma, 2*tau)\n",
    "    H = harris_response(J)\n",
    "\n",
    "    points = detect_interest_points(H)\n",
    "    desc = []\n",
    "\n",
    "    for t, y, x in points:\n",
    "        if (\n",
    "            t > 1 and y > 1 and x > 1 and\n",
    "            t < L.shape[0]-2 and\n",
    "            y < L.shape[1]-2 and\n",
    "            x < L.shape[2]-2\n",
    "        ):\n",
    "            desc.append(extract_jet(L, x, y, t, sigma, tau))\n",
    "\n",
    "    if len(desc) == 0:\n",
    "        return torch.empty((0, 6), device=device)\n",
    "\n",
    "    return torch.stack(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9dfb2",
   "metadata": {},
   "source": [
    "#### 2.6. Build Visual Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91171e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(train_samples, K=400, max_samples=100_000):\n",
    "    all_desc = []\n",
    "\n",
    "    for s in train_samples:\n",
    "        video = load_video(s[\"path\"])\n",
    "        video = video.to(device)\n",
    "        desc = extract_descriptors(video)\n",
    "        all_desc.append(desc)\n",
    "\n",
    "    X = torch.cat(all_desc).cpu().numpy()\n",
    "\n",
    "    if len(X) > max_samples:\n",
    "        idx = np.random.choice(len(X), max_samples, replace=False)\n",
    "        X = X[idx]\n",
    "\n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=K,\n",
    "        batch_size=4096,\n",
    "        random_state=0\n",
    "    )\n",
    "    kmeans.fit(X)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cedf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg4 @ 0x311d45880] ac-tex damaged at 8 6\n",
      "[mpeg4 @ 0x311d45880] Error at MB: 74\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning vocabulary...\")\n",
    "kmeans = build_vocabulary(train_samples, K)\n",
    "dump(kmeans, \"artifact/kmeans_K400.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afb4b8",
   "metadata": {},
   "source": [
    "#### 2.7. Encode Video as Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70baa5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_video(video, kmeans, K):\n",
    "    desc = extract_descriptors(video)\n",
    "\n",
    "    if desc.numel() == 0:\n",
    "        return torch.zeros(K)\n",
    "\n",
    "    labels = kmeans.predict(desc.cpu().numpy())\n",
    "    hist = np.bincount(labels, minlength=K).astype(np.float32)\n",
    "    hist /= (hist.sum() + 1e-8)\n",
    "\n",
    "    return torch.from_numpy(hist)\n",
    "\n",
    "def build_dataset(samples, kmeans, K):\n",
    "    X, y = [], []\n",
    "\n",
    "    for s in samples:\n",
    "        # Load video\n",
    "        video = load_video(s[\"path\"])\n",
    "        video = video.to(device)\n",
    "        \n",
    "\t\t# Encode video\n",
    "        hist = encode_video(video, kmeans, K)\n",
    "        \n",
    "\t\t# Build dataset\n",
    "        X.append(hist)\n",
    "        y.append(s[\"label\"])\n",
    "\n",
    "    return torch.stack(X), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c741439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg4 @ 0x3057ca5b0] ac-tex damaged at 8 6\n",
      "[mpeg4 @ 0x3057ca5b0] Error at MB: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train tensor([2.7688e-04, 6.7106e-03, 7.8764e-03, 1.2387e-04, 0.0000e+00, 2.9145e-05,\n",
      "        7.2862e-06, 3.0675e-03, 4.3717e-04, 7.8764e-03, 3.1258e-03, 7.7234e-03,\n",
      "        1.7392e-02, 3.4974e-04, 6.6086e-03, 2.1859e-05, 6.9729e-03, 1.9454e-03,\n",
      "        4.7360e-04, 6.8126e-03, 7.0676e-04, 5.7051e-03, 1.9090e-03, 9.6906e-04,\n",
      "        2.2150e-03, 6.3754e-03, 9.4720e-03, 5.8289e-05, 4.0074e-04, 7.2862e-06,\n",
      "        3.6431e-05, 2.5647e-03, 6.6304e-04, 7.7234e-04, 7.3590e-03, 3.4318e-03,\n",
      "        2.4773e-04, 1.9119e-02, 0.0000e+00, 1.1621e-02, 4.3717e-05, 8.7434e-05,\n",
      "        1.4572e-05, 5.2461e-04, 3.6431e-05, 0.0000e+00, 1.1002e-03, 5.7852e-03,\n",
      "        4.5174e-04, 3.4609e-03, 1.1665e-02, 0.0000e+00, 0.0000e+00, 6.9947e-04,\n",
      "        0.0000e+00, 5.1805e-03, 4.9692e-03, 6.5576e-05, 7.2862e-05, 0.0000e+00,\n",
      "        0.0000e+00, 7.2862e-06, 3.7087e-03, 3.6431e-05, 4.3717e-05, 1.3895e-02,\n",
      "        4.2989e-03, 0.0000e+00, 1.4572e-05, 3.6431e-05, 2.4044e-03, 1.3115e-04,\n",
      "        7.3590e-03, 1.7924e-03, 8.7361e-03, 1.4572e-05, 2.5137e-03, 1.2926e-02,\n",
      "        6.9219e-03, 3.2132e-03, 1.4572e-04, 0.0000e+00, 3.8107e-03, 2.1859e-05,\n",
      "        0.0000e+00, 2.1786e-03, 0.0000e+00, 2.6230e-04, 4.7142e-03, 5.8289e-05,\n",
      "        7.2133e-03, 5.7051e-03, 3.9491e-03, 0.0000e+00, 1.4572e-05, 6.4118e-04,\n",
      "        1.3188e-03, 1.4645e-03, 2.7250e-03, 1.0201e-03, 7.6796e-03, 0.0000e+00,\n",
      "        8.7580e-03, 0.0000e+00, 2.9728e-03, 6.7252e-03, 1.1658e-04, 2.2587e-04,\n",
      "        1.9673e-04, 0.0000e+00, 3.9200e-03, 3.5484e-03, 8.4447e-03, 2.1130e-04,\n",
      "        5.1003e-05, 7.2862e-06, 9.4210e-03, 1.8944e-04, 4.4154e-03, 4.8307e-03,\n",
      "        3.9637e-03, 1.4572e-04, 2.9145e-05, 5.8289e-05, 8.5686e-03, 4.3717e-05,\n",
      "        1.7414e-03, 5.2461e-04, 0.0000e+00, 1.2387e-04, 0.0000e+00, 4.6923e-03,\n",
      "        1.1556e-02, 1.2161e-02, 7.2862e-05, 3.9345e-04, 2.7760e-03, 6.1204e-04,\n",
      "        0.0000e+00, 2.2587e-04, 8.8163e-04, 0.0000e+00, 5.3189e-04, 9.3263e-04,\n",
      "        9.7198e-03, 2.4044e-04, 1.1483e-02, 5.3189e-04, 0.0000e+00, 9.4720e-05,\n",
      "        4.2260e-04, 6.1204e-04, 4.3717e-05, 4.8817e-04, 2.6376e-03, 1.6758e-03,\n",
      "        0.0000e+00, 8.7434e-05, 1.3844e-04, 1.3953e-02, 0.0000e+00, 6.5576e-04,\n",
      "        6.3026e-03, 0.0000e+00, 9.4720e-05, 2.5647e-03, 5.1003e-05, 4.2989e-03,\n",
      "        1.4572e-05, 7.2862e-06, 0.0000e+00, 0.0000e+00, 3.6431e-05, 3.2788e-04,\n",
      "        2.1859e-04, 4.7214e-03, 8.0148e-04, 0.0000e+00, 3.9345e-04, 7.2862e-06,\n",
      "        4.6632e-03, 7.2862e-06, 1.6758e-04, 8.7434e-05, 7.2862e-05, 2.8780e-03,\n",
      "        3.4974e-04, 0.0000e+00, 1.2532e-03, 0.0000e+00, 1.0682e-02, 1.3691e-02,\n",
      "        2.6740e-03, 2.7688e-04, 0.0000e+00, 0.0000e+00, 2.1859e-04, 2.4044e-04,\n",
      "        0.0000e+00, 3.7160e-04, 5.5448e-03, 2.9145e-05, 4.4227e-03, 7.2862e-05,\n",
      "        1.4653e-02, 3.6431e-05, 6.1933e-04, 5.2461e-04, 2.1421e-03, 1.5665e-03,\n",
      "        1.5520e-03, 4.8817e-04, 1.2263e-02, 1.5184e-02, 9.3773e-03, 1.4572e-05,\n",
      "        2.3316e-04, 0.0000e+00, 1.8412e-02, 1.5010e-03, 8.0148e-05, 1.5665e-03,\n",
      "        5.0275e-03, 1.1483e-02, 7.2862e-06, 1.2387e-04, 0.0000e+00, 6.3026e-03,\n",
      "        2.0474e-03, 2.4044e-04, 1.7633e-03, 1.8215e-04, 1.2336e-02, 5.1878e-03,\n",
      "        0.0000e+00, 3.8908e-03, 2.0372e-02, 9.0203e-03, 1.9454e-03, 7.2862e-06,\n",
      "        4.9546e-04, 1.1658e-04, 5.4719e-03, 2.1859e-05, 1.4354e-03, 9.1077e-03,\n",
      "        2.4190e-03, 6.2661e-04, 0.0000e+00, 5.4355e-03, 8.6123e-03, 1.0565e-03,\n",
      "        8.1605e-04, 1.3115e-04, 1.0492e-03, 0.0000e+00, 3.4026e-03, 7.2862e-06,\n",
      "        1.2634e-02, 0.0000e+00, 2.5502e-04, 3.9345e-04, 7.5048e-03, 3.4245e-04,\n",
      "        2.1859e-05, 0.0000e+00, 3.6431e-04, 1.1366e-03, 4.3717e-05, 4.7142e-03,\n",
      "        3.1331e-04, 0.0000e+00, 4.6340e-03, 4.9546e-04, 3.6941e-03, 1.0055e-03,\n",
      "        0.0000e+00, 2.9145e-05, 1.7268e-03, 1.5301e-03, 3.6504e-03, 1.5665e-03,\n",
      "        0.0000e+00, 2.0984e-03, 1.6030e-04, 2.0401e-04, 6.8490e-04, 0.0000e+00,\n",
      "        4.2989e-04, 0.0000e+00, 3.7742e-03, 5.9820e-03, 1.3989e-03, 0.0000e+00,\n",
      "        3.2132e-03, 9.6178e-04, 0.0000e+00, 2.6376e-03, 1.8507e-03, 9.4720e-04,\n",
      "        2.3389e-03, 5.1003e-05, 0.0000e+00, 1.2234e-02, 3.5047e-03, 2.6230e-04,\n",
      "        0.0000e+00, 1.5884e-03, 7.2862e-06, 2.1130e-04, 5.6832e-04, 0.0000e+00,\n",
      "        0.0000e+00, 8.9620e-04, 0.0000e+00, 2.2441e-03, 0.0000e+00, 2.5502e-04,\n",
      "        3.3516e-04, 3.4245e-04, 0.0000e+00, 2.1859e-05, 6.1933e-04, 1.7997e-03,\n",
      "        8.5248e-04, 0.0000e+00, 0.0000e+00, 1.7341e-03, 1.9381e-03, 2.4052e-02,\n",
      "        2.4773e-04, 1.0128e-02, 1.1818e-02, 7.2862e-05, 2.1859e-05, 2.0401e-04,\n",
      "        2.6740e-03, 1.0638e-03, 3.2059e-04, 7.2862e-06, 1.0929e-04, 1.2387e-04,\n",
      "        1.4449e-02, 0.0000e+00, 2.1859e-05, 4.7797e-03, 2.6522e-03, 4.6632e-04,\n",
      "        9.9821e-04, 2.0110e-03, 0.0000e+00, 1.7195e-02, 2.9145e-05, 0.0000e+00,\n",
      "        7.2862e-06, 1.7487e-04, 4.0074e-04, 2.3170e-03, 8.9256e-03, 1.8944e-04,\n",
      "        8.0148e-05, 7.4028e-03, 2.1859e-05, 0.0000e+00, 1.4500e-03, 6.9802e-03,\n",
      "        1.7705e-03, 3.6431e-05, 0.0000e+00, 0.0000e+00, 5.2096e-03, 1.3101e-02,\n",
      "        1.6102e-03, 5.3481e-03, 1.4937e-03, 0.0000e+00, 7.3590e-04, 5.0420e-03,\n",
      "        2.7833e-03, 0.0000e+00, 0.0000e+00, 9.8364e-04, 0.0000e+00, 2.7105e-03,\n",
      "        1.0929e-03, 2.0620e-03, 0.0000e+00, 5.4501e-03, 2.9145e-05, 0.0000e+00,\n",
      "        2.2587e-03, 5.8289e-05, 7.5558e-03, 0.0000e+00, 1.6758e-04, 9.3263e-04,\n",
      "        0.0000e+00, 4.0803e-03, 5.3918e-04, 0.0000e+00]) y_train tensor(0)\n",
      "X_val tensor([0.0012, 0.0025, 0.0071, 0.0004, 0.0008, 0.0002, 0.0029, 0.0051, 0.0020,\n",
      "        0.0037, 0.0054, 0.0010, 0.0017, 0.0090, 0.0002, 0.0003, 0.0021, 0.0033,\n",
      "        0.0049, 0.0076, 0.0000, 0.0024, 0.0000, 0.0031, 0.0087, 0.0007, 0.0087,\n",
      "        0.0000, 0.0116, 0.0008, 0.0008, 0.0012, 0.0014, 0.0030, 0.0050, 0.0017,\n",
      "        0.0004, 0.0021, 0.0042, 0.0035, 0.0026, 0.0039, 0.0015, 0.0029, 0.0001,\n",
      "        0.0057, 0.0039, 0.0025, 0.0015, 0.0015, 0.0056, 0.0000, 0.0002, 0.0006,\n",
      "        0.0020, 0.0036, 0.0033, 0.0000, 0.0005, 0.0030, 0.0046, 0.0017, 0.0025,\n",
      "        0.0024, 0.0024, 0.0034, 0.0046, 0.0000, 0.0016, 0.0026, 0.0033, 0.0043,\n",
      "        0.0011, 0.0015, 0.0034, 0.0000, 0.0039, 0.0023, 0.0013, 0.0050, 0.0106,\n",
      "        0.0000, 0.0022, 0.0008, 0.0052, 0.0000, 0.0002, 0.0033, 0.0029, 0.0002,\n",
      "        0.0019, 0.0034, 0.0020, 0.0012, 0.0006, 0.0002, 0.0028, 0.0019, 0.0054,\n",
      "        0.0051, 0.0005, 0.0042, 0.0021, 0.0030, 0.0024, 0.0022, 0.0013, 0.0005,\n",
      "        0.0013, 0.0014, 0.0005, 0.0027, 0.0020, 0.0063, 0.0006, 0.0004, 0.0030,\n",
      "        0.0021, 0.0040, 0.0012, 0.0030, 0.0042, 0.0021, 0.0022, 0.0039, 0.0036,\n",
      "        0.0052, 0.0022, 0.0000, 0.0074, 0.0001, 0.0011, 0.0016, 0.0021, 0.0014,\n",
      "        0.0022, 0.0013, 0.0003, 0.0000, 0.0000, 0.0028, 0.0000, 0.0038, 0.0000,\n",
      "        0.0021, 0.0165, 0.0043, 0.0012, 0.0001, 0.0011, 0.0001, 0.0014, 0.0055,\n",
      "        0.0047, 0.0005, 0.0026, 0.0019, 0.0037, 0.0066, 0.0033, 0.0003, 0.0000,\n",
      "        0.0065, 0.0000, 0.0021, 0.0019, 0.0044, 0.0003, 0.0000, 0.0073, 0.0000,\n",
      "        0.0058, 0.0000, 0.0038, 0.0010, 0.0027, 0.0031, 0.0013, 0.0022, 0.0037,\n",
      "        0.0011, 0.0022, 0.0016, 0.0039, 0.0020, 0.0011, 0.0013, 0.0002, 0.0079,\n",
      "        0.0016, 0.0022, 0.0022, 0.0001, 0.0019, 0.0002, 0.0002, 0.0004, 0.0040,\n",
      "        0.0109, 0.0009, 0.0003, 0.0038, 0.0085, 0.0012, 0.0043, 0.0000, 0.0052,\n",
      "        0.0005, 0.0013, 0.0000, 0.0066, 0.0004, 0.0059, 0.0014, 0.0036, 0.0004,\n",
      "        0.0006, 0.0003, 0.0043, 0.0041, 0.0002, 0.0024, 0.0047, 0.0008, 0.0000,\n",
      "        0.0031, 0.0000, 0.0042, 0.0021, 0.0000, 0.0004, 0.0052, 0.0007, 0.0037,\n",
      "        0.0000, 0.0014, 0.0075, 0.0089, 0.0020, 0.0033, 0.0031, 0.0025, 0.0048,\n",
      "        0.0006, 0.0020, 0.0037, 0.0014, 0.0002, 0.0003, 0.0011, 0.0010, 0.0000,\n",
      "        0.0001, 0.0004, 0.0021, 0.0004, 0.0036, 0.0000, 0.0032, 0.0015, 0.0008,\n",
      "        0.0016, 0.0028, 0.0015, 0.0035, 0.0000, 0.0033, 0.0016, 0.0000, 0.0032,\n",
      "        0.0000, 0.0000, 0.0010, 0.0029, 0.0005, 0.0046, 0.0012, 0.0054, 0.0015,\n",
      "        0.0132, 0.0048, 0.0045, 0.0002, 0.0013, 0.0036, 0.0039, 0.0014, 0.0011,\n",
      "        0.0119, 0.0000, 0.0035, 0.0007, 0.0044, 0.0000, 0.0000, 0.0004, 0.0006,\n",
      "        0.0000, 0.0000, 0.0000, 0.0052, 0.0001, 0.0000, 0.0008, 0.0035, 0.0005,\n",
      "        0.0020, 0.0035, 0.0014, 0.0009, 0.0130, 0.0008, 0.0007, 0.0005, 0.0000,\n",
      "        0.0071, 0.0003, 0.0001, 0.0025, 0.0024, 0.0003, 0.0038, 0.0024, 0.0042,\n",
      "        0.0019, 0.0000, 0.0011, 0.0059, 0.0033, 0.0008, 0.0011, 0.0045, 0.0035,\n",
      "        0.0000, 0.0129, 0.0010, 0.0075, 0.0045, 0.0017, 0.0058, 0.0087, 0.0000,\n",
      "        0.0015, 0.0038, 0.0004, 0.0026, 0.0000, 0.0033, 0.0040, 0.0005, 0.0000,\n",
      "        0.0033, 0.0009, 0.0035, 0.0013, 0.0003, 0.0000, 0.0092, 0.0011, 0.0012,\n",
      "        0.0011, 0.0048, 0.0000, 0.0000, 0.0002, 0.0009, 0.0033, 0.0059, 0.0020,\n",
      "        0.0014, 0.0076, 0.0038, 0.0116, 0.0006, 0.0012, 0.0000, 0.0023, 0.0015,\n",
      "        0.0031, 0.0004, 0.0013, 0.0019, 0.0014, 0.0012, 0.0000, 0.0161, 0.0000,\n",
      "        0.0022, 0.0025, 0.0002, 0.0023, 0.0021, 0.0019, 0.0009, 0.0070, 0.0032,\n",
      "        0.0033, 0.0012, 0.0022, 0.0048]) y_val tensor(4)\n",
      "X_test tensor([2.9043e-03, 1.0561e-03, 3.2563e-03, 4.5765e-03, 8.8009e-05, 1.3069e-02,\n",
      "        1.5842e-03, 6.3806e-03, 1.8482e-03, 8.8009e-04, 8.3168e-03, 2.1122e-03,\n",
      "        3.3443e-03, 1.3201e-04, 1.9802e-03, 3.5204e-03, 3.9164e-03, 1.0121e-03,\n",
      "        5.2805e-04, 1.0121e-02, 2.2442e-03, 2.5083e-03, 5.9846e-03, 4.7965e-03,\n",
      "        7.7008e-03, 3.0803e-03, 4.1804e-03, 1.2761e-03, 2.1122e-03, 3.5204e-04,\n",
      "        0.0000e+00, 4.0484e-03, 4.4004e-03, 6.1606e-04, 3.0363e-03, 3.2563e-03,\n",
      "        7.0407e-04, 3.4323e-03, 0.0000e+00, 7.4807e-03, 2.4642e-03, 8.8009e-04,\n",
      "        6.1606e-04, 3.4323e-03, 1.4081e-03, 0.0000e+00, 4.8845e-03, 6.1606e-04,\n",
      "        4.8405e-04, 6.2486e-03, 7.3487e-03, 0.0000e+00, 6.1606e-04, 3.8724e-03,\n",
      "        0.0000e+00, 2.5083e-03, 8.4048e-03, 2.9923e-03, 1.4081e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.5842e-03, 7.9208e-03, 6.1606e-04, 1.7602e-04, 9.6810e-04,\n",
      "        5.7206e-03, 7.4807e-04, 1.0121e-03, 0.0000e+00, 3.6524e-03, 0.0000e+00,\n",
      "        1.4521e-03, 6.6887e-03, 6.1606e-03, 9.6810e-04, 4.4004e-03, 1.2761e-03,\n",
      "        1.5842e-03, 1.1441e-03, 4.9725e-03, 1.7602e-03, 6.2926e-03, 9.2409e-04,\n",
      "        0.0000e+00, 2.4642e-03, 0.0000e+00, 2.7723e-03, 1.2761e-03, 5.3245e-03,\n",
      "        4.9725e-03, 2.6843e-03, 4.4444e-03, 0.0000e+00, 0.0000e+00, 4.2684e-03,\n",
      "        7.7008e-03, 2.6843e-03, 4.4004e-05, 4.2684e-03, 4.4004e-03, 8.8009e-05,\n",
      "        4.9285e-03, 8.8009e-04, 4.0484e-03, 1.0121e-03, 3.3003e-03, 0.0000e+00,\n",
      "        6.3366e-03, 0.0000e+00, 7.9648e-03, 1.1441e-03, 4.8405e-03, 2.3322e-03,\n",
      "        8.8009e-05, 4.4004e-05, 6.4686e-03, 1.6722e-03, 1.8922e-03, 5.5446e-03,\n",
      "        3.8724e-03, 1.5842e-03, 8.8009e-04, 0.0000e+00, 7.3487e-03, 4.4004e-04,\n",
      "        2.4202e-03, 2.1562e-03, 0.0000e+00, 7.9208e-04, 0.0000e+00, 3.3883e-03,\n",
      "        3.8724e-03, 3.9164e-03, 3.7404e-03, 3.3003e-03, 1.5842e-03, 3.1243e-03,\n",
      "        2.6403e-04, 1.1441e-03, 6.2046e-03, 2.6403e-04, 3.6964e-03, 5.5005e-03,\n",
      "        1.4521e-03, 1.1001e-03, 7.0407e-04, 3.1243e-03, 3.5204e-04, 1.3201e-03,\n",
      "        2.5083e-03, 4.0044e-03, 4.9285e-03, 1.0121e-03, 1.0209e-02, 8.9769e-03,\n",
      "        0.0000e+00, 2.6843e-03, 3.0803e-04, 8.5369e-03, 0.0000e+00, 5.8526e-03,\n",
      "        8.8009e-05, 0.0000e+00, 4.6645e-03, 8.0528e-03, 6.6007e-03, 2.8603e-03,\n",
      "        1.0561e-03, 0.0000e+00, 4.4004e-05, 0.0000e+00, 4.8405e-04, 6.1606e-04,\n",
      "        2.8603e-03, 2.5963e-03, 1.3157e-02, 8.8009e-05, 6.4246e-03, 4.4004e-04,\n",
      "        2.1562e-03, 0.0000e+00, 4.7085e-03, 2.6843e-03, 1.4081e-03, 1.4081e-03,\n",
      "        3.4763e-03, 0.0000e+00, 2.5963e-03, 0.0000e+00, 2.0682e-03, 1.8482e-03,\n",
      "        3.7404e-03, 2.9483e-03, 8.8009e-04, 4.4004e-05, 1.8482e-03, 2.1122e-03,\n",
      "        0.0000e+00, 3.2123e-03, 3.1683e-03, 0.0000e+00, 1.9362e-03, 3.5644e-03,\n",
      "        1.7602e-03, 2.2002e-04, 0.0000e+00, 5.7206e-04, 1.7602e-04, 7.4807e-04,\n",
      "        2.5083e-03, 1.4521e-03, 9.2409e-04, 9.2409e-04, 6.5127e-03, 4.8405e-04,\n",
      "        4.9285e-03, 0.0000e+00, 6.4246e-03, 4.0924e-03, 6.1606e-04, 6.2926e-03,\n",
      "        7.3927e-03, 1.8042e-03, 2.2002e-04, 8.8009e-04, 0.0000e+00, 9.1529e-03,\n",
      "        5.6326e-03, 1.3201e-03, 4.4004e-03, 4.9285e-03, 6.6007e-04, 1.5842e-03,\n",
      "        4.4004e-05, 7.2607e-03, 1.8482e-03, 4.1804e-03, 6.1166e-03, 0.0000e+00,\n",
      "        4.4004e-05, 0.0000e+00, 3.5204e-03, 5.2805e-04, 2.2882e-03, 2.2882e-03,\n",
      "        2.2002e-04, 9.6810e-04, 0.0000e+00, 5.2805e-04, 1.5402e-03, 2.5083e-03,\n",
      "        8.1408e-03, 5.2805e-04, 1.0121e-03, 2.6403e-04, 4.6645e-03, 1.1441e-03,\n",
      "        5.2805e-04, 0.0000e+00, 2.6403e-04, 4.5325e-03, 1.1441e-03, 4.4444e-03,\n",
      "        4.8405e-04, 1.3641e-03, 1.5842e-03, 3.1683e-03, 1.2321e-03, 4.5765e-03,\n",
      "        1.9802e-03, 3.5204e-04, 5.0165e-03, 1.8922e-03, 6.8207e-03, 2.3762e-03,\n",
      "        2.2002e-04, 3.5204e-04, 5.6766e-03, 4.1364e-03, 8.8009e-04, 0.0000e+00,\n",
      "        0.0000e+00, 5.4125e-03, 1.8042e-03, 1.7162e-03, 6.1606e-04, 8.8009e-04,\n",
      "        1.1001e-03, 0.0000e+00, 5.7206e-04, 1.5842e-03, 7.0847e-03, 0.0000e+00,\n",
      "        5.8086e-03, 3.9604e-03, 1.3201e-04, 4.0924e-03, 5.0165e-03, 2.5523e-03,\n",
      "        7.9208e-03, 3.9604e-04, 1.7602e-04, 1.8042e-03, 2.7283e-03, 7.4807e-04,\n",
      "        0.0000e+00, 4.1364e-03, 2.1562e-03, 1.2761e-03, 1.5402e-03, 0.0000e+00,\n",
      "        6.6007e-04, 1.1881e-03, 3.0803e-04, 1.7602e-04, 1.3201e-04, 7.9208e-04,\n",
      "        4.6205e-03, 1.7602e-03, 0.0000e+00, 4.4004e-05, 2.3762e-03, 9.1969e-03,\n",
      "        4.1804e-03, 0.0000e+00, 0.0000e+00, 3.4323e-03, 3.7404e-03, 1.3201e-03,\n",
      "        3.3003e-03, 3.0363e-03, 3.7844e-03, 1.3201e-04, 1.5842e-03, 4.8405e-04,\n",
      "        1.2937e-02, 3.1243e-03, 7.8768e-03, 0.0000e+00, 5.2805e-04, 1.8922e-03,\n",
      "        2.2882e-03, 9.6810e-04, 1.0121e-03, 2.6843e-03, 3.3443e-03, 3.9164e-03,\n",
      "        1.0561e-03, 9.6810e-04, 4.4004e-05, 3.8724e-03, 4.4004e-05, 8.8009e-05,\n",
      "        0.0000e+00, 5.2805e-04, 4.8405e-04, 7.4367e-03, 3.2563e-03, 1.0121e-03,\n",
      "        2.7723e-03, 3.4763e-03, 9.6810e-04, 8.8009e-05, 1.9362e-03, 3.4763e-03,\n",
      "        2.2002e-03, 1.0121e-03, 0.0000e+00, 0.0000e+00, 2.6403e-04, 6.4686e-03,\n",
      "        2.2002e-04, 3.4323e-03, 4.0484e-03, 0.0000e+00, 6.2486e-03, 2.6403e-03,\n",
      "        3.6084e-03, 7.0407e-04, 0.0000e+00, 6.5127e-03, 0.0000e+00, 3.7404e-03,\n",
      "        8.5369e-03, 1.1397e-02, 0.0000e+00, 5.8966e-03, 1.4081e-03, 1.2321e-03,\n",
      "        2.1122e-03, 1.9802e-03, 4.0924e-03, 0.0000e+00, 0.0000e+00, 1.0561e-03,\n",
      "        1.2321e-03, 2.5523e-03, 2.2442e-03, 0.0000e+00]) y_test tensor(2)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = build_dataset(train_samples, kmeans, K)\n",
    "X_val, y_val = build_dataset(val_samples, kmeans, K)\n",
    "X_test, y_test = build_dataset(test_samples, kmeans, K)\n",
    "\n",
    "print(\"X_train\", X_train[0], \"y_train\", y_train[0])\n",
    "print(\"X_val\", X_val[0], \"y_val\", y_val[0])\n",
    "print(\"X_test\", X_test[0], \"y_test\", y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\"artifact\")\n",
    "torch.save({\n",
    "\t\"k\": 400,\n",
    "\t\"actions\": [\"boxing\", \"handclapping\", \"handwaving\", \"jogging\", \"running\", \"walking\" ],\n",
    "\t\"X_train\": X_train, \"y_train\": y_train,\n",
    "\t\"X_val\": X_val, \"y_val\": y_val,\n",
    "\t\"X_test\": X_test, \"y_test\": y_test,\n",
    "}, save_dir / \"kth_features.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62434c46",
   "metadata": {},
   "source": [
    "### 3. Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f015938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X.numpy())\n",
    "\n",
    "    clf = LinearSVC(C=1.0, max_iter=5000)\n",
    "    clf.fit(Xs, y.numpy())\n",
    "\n",
    "    return clf, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55702cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training classifier...\")\n",
    "clf, scaler = train_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2ce04",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c6abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, scaler, X, y):\n",
    "    Xs = scaler.transform(X.numpy())\n",
    "    y_pred = clf.predict(Xs)\n",
    "\n",
    "    acc = accuracy_score(y.numpy(), y_pred)\n",
    "    cm = confusion_matrix(y.numpy(), y_pred)\n",
    "\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Validation ----\n",
      "Val accuracy: 79.17%\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Validation ----\")\n",
    "val_acc, _ = evaluate(clf, scaler, X_val, y_val)\n",
    "print(f\"Val accuracy: {val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4b746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Test ----\n",
      "Test accuracy: 71.88%\n",
      "[[ 7  6  3  0  0  0]\n",
      " [ 1 14  0  1  0  0]\n",
      " [ 2  0 12  0  1  1]\n",
      " [ 0  0  1 13  2  0]\n",
      " [ 0  0  0  6  9  1]\n",
      " [ 0  1  0  1  0 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"---- Test ----\")\n",
    "test_acc, cm = evaluate(clf, scaler, X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce0838",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-action",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
